{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc43fab5-015e-4bd1-b3fa-edf7dc522d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Flatten,Conv2D,MaxPooling2D\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils \n",
    "from keras import backend as K \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d29e626d-161c-48ac-be8d-7b67d4eca2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "# let's load data \n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fe0d797-8c41-406c-95e9-4a8919e9a12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing inputs from 0-255 to 0.0-1.0 \n",
    "X_train = X_train.astype('float32') \n",
    "X_test = X_test.astype('float32') \n",
    "X_train = X_train / 255.0 \n",
    "X_test = X_test / 255.q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7850c3ab-471d-4467-af04-c356e1050057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode outputs \n",
    "y_train = np_utils.to_categorical(y_train) \n",
    "y_test = np_utils.to_categorical(y_test) \n",
    "num_classes = y_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fb66bdbb-4956-46ae-94c9-589d30f7d920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 10)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "328feeae-b585-4d71-964a-082ec35deb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model \n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(32,32,3), activation='relu', padding='same')) \n",
    "model.add(Dropout(0.2)) \n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same')) \n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same')) \n",
    "model.add(Dropout(0.2)) \n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same')) \n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same')) \n",
    "model.add(Dropout(0.2)) \n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same')) \n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "model.add(Flatten()) \n",
    "model.add(Dropout(0.2)) \n",
    "model.add(Dense(1024, activation='relu', kernel_constraint=maxnorm(3))) \n",
    "model.add(Dropout(0.2)) \n",
    "model.add(Dense(512, activation='relu', kernel_constraint=maxnorm(3))) \n",
    "model.add(Dropout(0.2)) \n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa2f97b3-b933-43e0-a648-1db05df4e513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 32, 32, 32)        0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 32, 32, 32)        9248      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 16, 16, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 16, 16, 64)        18496     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 16, 16, 64)        0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 16, 16, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 8, 8, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 8, 8, 128)         0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 4, 4, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2048)              0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              2098176   \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                5130      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,915,114\n",
      "Trainable params: 2,915,114\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffef95da-8c23-4bfa-ad9a-4878a2bd09b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model \n",
    "lrate = 0.01 \n",
    "\n",
    "# sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False) \n",
    "# model.compile(loss='categorical_crossentropy', optimizer='adam', epochs=20, metrics=['accuracy'])\n",
    "# optimum=Adam(learning_rate=0.001)\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "adcecbed-1318-4dc9-ba3c-f68a3d8834d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "1563/1563 [==============================] - 16s 10ms/step - loss: 0.4009 - accuracy: 0.8683 - val_loss: 0.6607 - val_accuracy: 0.8023\n",
      "Epoch 2/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3915 - accuracy: 0.8757 - val_loss: 0.6161 - val_accuracy: 0.8104\n",
      "Epoch 3/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3880 - accuracy: 0.8738 - val_loss: 0.6425 - val_accuracy: 0.8065\n",
      "Epoch 4/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4032 - accuracy: 0.8700 - val_loss: 0.6371 - val_accuracy: 0.7999\n",
      "Epoch 5/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3980 - accuracy: 0.8707 - val_loss: 0.6246 - val_accuracy: 0.8089\n",
      "Epoch 6/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3851 - accuracy: 0.8773 - val_loss: 0.6343 - val_accuracy: 0.8076\n",
      "Epoch 7/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3795 - accuracy: 0.8762 - val_loss: 0.6455 - val_accuracy: 0.8055\n",
      "Epoch 8/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3847 - accuracy: 0.8749 - val_loss: 0.6022 - val_accuracy: 0.8109\n",
      "Epoch 9/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3930 - accuracy: 0.8734 - val_loss: 0.6143 - val_accuracy: 0.8221\n",
      "Epoch 10/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4015 - accuracy: 0.8738 - val_loss: 0.6240 - val_accuracy: 0.8099\n",
      "Epoch 11/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3868 - accuracy: 0.8762 - val_loss: 0.6190 - val_accuracy: 0.8146\n",
      "Epoch 12/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3835 - accuracy: 0.8775 - val_loss: 0.6607 - val_accuracy: 0.7959\n",
      "Epoch 13/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3839 - accuracy: 0.8745 - val_loss: 0.6587 - val_accuracy: 0.8054\n",
      "Epoch 14/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3998 - accuracy: 0.8725 - val_loss: 0.6397 - val_accuracy: 0.8036\n",
      "Epoch 15/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4013 - accuracy: 0.8718 - val_loss: 0.6435 - val_accuracy: 0.8027\n",
      "Epoch 16/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3937 - accuracy: 0.8722 - val_loss: 0.6630 - val_accuracy: 0.8100\n",
      "Epoch 17/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3978 - accuracy: 0.8739 - val_loss: 0.6183 - val_accuracy: 0.8091\n",
      "Epoch 18/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3868 - accuracy: 0.8767 - val_loss: 0.6671 - val_accuracy: 0.8075\n",
      "Epoch 19/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3893 - accuracy: 0.8756 - val_loss: 0.6260 - val_accuracy: 0.8098\n",
      "Epoch 20/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4002 - accuracy: 0.8737 - val_loss: 0.6460 - val_accuracy: 0.8095\n",
      "Epoch 21/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4116 - accuracy: 0.8695 - val_loss: 0.7056 - val_accuracy: 0.7891\n",
      "Epoch 22/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4003 - accuracy: 0.8723 - val_loss: 0.6363 - val_accuracy: 0.8156\n",
      "Epoch 23/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3823 - accuracy: 0.8789 - val_loss: 0.6930 - val_accuracy: 0.7886\n",
      "Epoch 24/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4075 - accuracy: 0.8708 - val_loss: 0.6628 - val_accuracy: 0.8023\n",
      "Epoch 25/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3825 - accuracy: 0.8783 - val_loss: 0.6755 - val_accuracy: 0.8141\n",
      "Epoch 26/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3818 - accuracy: 0.8780 - val_loss: 0.6268 - val_accuracy: 0.8063\n",
      "Epoch 27/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3853 - accuracy: 0.8765 - val_loss: 0.6376 - val_accuracy: 0.8149\n",
      "Epoch 28/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3769 - accuracy: 0.8798 - val_loss: 0.6313 - val_accuracy: 0.8036\n",
      "Epoch 29/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3872 - accuracy: 0.8752 - val_loss: 0.6639 - val_accuracy: 0.8030\n",
      "Epoch 30/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3911 - accuracy: 0.8756 - val_loss: 0.6104 - val_accuracy: 0.8167\n",
      "Epoch 31/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3771 - accuracy: 0.8782 - val_loss: 0.6725 - val_accuracy: 0.8113\n",
      "Epoch 32/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4076 - accuracy: 0.8715 - val_loss: 0.6766 - val_accuracy: 0.8021\n",
      "Epoch 33/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3791 - accuracy: 0.8782 - val_loss: 0.6825 - val_accuracy: 0.8016\n",
      "Epoch 34/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3799 - accuracy: 0.8772 - val_loss: 0.6726 - val_accuracy: 0.8053\n",
      "Epoch 35/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3944 - accuracy: 0.8759 - val_loss: 0.6724 - val_accuracy: 0.8036\n",
      "Epoch 36/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4086 - accuracy: 0.8720 - val_loss: 0.6129 - val_accuracy: 0.8087\n",
      "Epoch 37/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3813 - accuracy: 0.8776 - val_loss: 0.6580 - val_accuracy: 0.8041\n",
      "Epoch 38/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3888 - accuracy: 0.8755 - val_loss: 0.6504 - val_accuracy: 0.8003\n",
      "Epoch 39/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3965 - accuracy: 0.8746 - val_loss: 0.6368 - val_accuracy: 0.8181\n",
      "Epoch 40/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4018 - accuracy: 0.8715 - val_loss: 0.6375 - val_accuracy: 0.8085\n",
      "Epoch 41/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4495 - accuracy: 0.8584 - val_loss: 0.7074 - val_accuracy: 0.7973\n",
      "Epoch 42/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4108 - accuracy: 0.8700 - val_loss: 0.6519 - val_accuracy: 0.8037\n",
      "Epoch 43/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3872 - accuracy: 0.8772 - val_loss: 0.6865 - val_accuracy: 0.8072\n",
      "Epoch 44/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3775 - accuracy: 0.8809 - val_loss: 0.6851 - val_accuracy: 0.8116\n",
      "Epoch 45/150\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.3872 - accuracy: 0.8774 - val_loss: 0.6428 - val_accuracy: 0.8041\n",
      "Epoch 46/150\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.4007 - accuracy: 0.8717 - val_loss: 0.6684 - val_accuracy: 0.8084\n",
      "Epoch 47/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4009 - accuracy: 0.8745 - val_loss: 0.6963 - val_accuracy: 0.8031\n",
      "Epoch 48/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3908 - accuracy: 0.8760 - val_loss: 0.6332 - val_accuracy: 0.8056\n",
      "Epoch 49/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3970 - accuracy: 0.8732 - val_loss: 0.6798 - val_accuracy: 0.7957\n",
      "Epoch 50/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3926 - accuracy: 0.8749 - val_loss: 0.6553 - val_accuracy: 0.7978\n",
      "Epoch 51/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3978 - accuracy: 0.8735 - val_loss: 0.6898 - val_accuracy: 0.7914\n",
      "Epoch 52/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4051 - accuracy: 0.8725 - val_loss: 0.6338 - val_accuracy: 0.8109\n",
      "Epoch 53/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3918 - accuracy: 0.8760 - val_loss: 0.6673 - val_accuracy: 0.8027\n",
      "Epoch 54/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3868 - accuracy: 0.8769 - val_loss: 0.7427 - val_accuracy: 0.7891\n",
      "Epoch 55/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3995 - accuracy: 0.8720 - val_loss: 0.6733 - val_accuracy: 0.8103\n",
      "Epoch 56/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3897 - accuracy: 0.8769 - val_loss: 0.6516 - val_accuracy: 0.8094\n",
      "Epoch 57/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4002 - accuracy: 0.8729 - val_loss: 0.6886 - val_accuracy: 0.7896\n",
      "Epoch 58/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3827 - accuracy: 0.8794 - val_loss: 0.6395 - val_accuracy: 0.8165\n",
      "Epoch 59/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3983 - accuracy: 0.8760 - val_loss: 0.6476 - val_accuracy: 0.8062\n",
      "Epoch 60/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3946 - accuracy: 0.8756 - val_loss: 0.6578 - val_accuracy: 0.8071\n",
      "Epoch 61/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3836 - accuracy: 0.8780 - val_loss: 0.6482 - val_accuracy: 0.8027\n",
      "Epoch 62/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3924 - accuracy: 0.8758 - val_loss: 0.7220 - val_accuracy: 0.7959\n",
      "Epoch 63/150\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.3845 - accuracy: 0.8786 - val_loss: 0.6548 - val_accuracy: 0.8029\n",
      "Epoch 64/150\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.4256 - accuracy: 0.8663 - val_loss: 0.6333 - val_accuracy: 0.8096\n",
      "Epoch 65/150\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.4053 - accuracy: 0.8725 - val_loss: 0.6005 - val_accuracy: 0.8138\n",
      "Epoch 66/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3968 - accuracy: 0.8755 - val_loss: 0.6364 - val_accuracy: 0.8139\n",
      "Epoch 67/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3905 - accuracy: 0.8745 - val_loss: 0.6915 - val_accuracy: 0.8155\n",
      "Epoch 68/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3786 - accuracy: 0.8791 - val_loss: 0.6776 - val_accuracy: 0.8017\n",
      "Epoch 69/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4099 - accuracy: 0.8715 - val_loss: 0.6643 - val_accuracy: 0.7993\n",
      "Epoch 70/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3812 - accuracy: 0.8794 - val_loss: 0.6382 - val_accuracy: 0.8075\n",
      "Epoch 71/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3995 - accuracy: 0.8742 - val_loss: 0.6561 - val_accuracy: 0.8080\n",
      "Epoch 72/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3852 - accuracy: 0.8777 - val_loss: 0.6952 - val_accuracy: 0.7944\n",
      "Epoch 73/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3951 - accuracy: 0.8750 - val_loss: 0.6922 - val_accuracy: 0.7907\n",
      "Epoch 74/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3895 - accuracy: 0.8794 - val_loss: 0.6601 - val_accuracy: 0.8159\n",
      "Epoch 75/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3921 - accuracy: 0.8756 - val_loss: 0.7053 - val_accuracy: 0.7833\n",
      "Epoch 76/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4174 - accuracy: 0.8692 - val_loss: 0.6846 - val_accuracy: 0.8206\n",
      "Epoch 77/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4039 - accuracy: 0.8747 - val_loss: 0.6602 - val_accuracy: 0.8033\n",
      "Epoch 78/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4077 - accuracy: 0.8700 - val_loss: 0.6662 - val_accuracy: 0.8036\n",
      "Epoch 79/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4015 - accuracy: 0.8756 - val_loss: 0.7055 - val_accuracy: 0.8004\n",
      "Epoch 80/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4260 - accuracy: 0.8680 - val_loss: 0.7505 - val_accuracy: 0.7885\n",
      "Epoch 81/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4024 - accuracy: 0.8734 - val_loss: 0.6106 - val_accuracy: 0.8247\n",
      "Epoch 82/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4319 - accuracy: 0.8648 - val_loss: 0.6711 - val_accuracy: 0.8008\n",
      "Epoch 83/150\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.3790 - accuracy: 0.8800 - val_loss: 0.6763 - val_accuracy: 0.8095\n",
      "Epoch 84/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4247 - accuracy: 0.8678 - val_loss: 0.6846 - val_accuracy: 0.8049\n",
      "Epoch 85/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3908 - accuracy: 0.8748 - val_loss: 0.6800 - val_accuracy: 0.8061\n",
      "Epoch 86/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4083 - accuracy: 0.8715 - val_loss: 0.6612 - val_accuracy: 0.8038\n",
      "Epoch 87/150\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.3872 - accuracy: 0.8773 - val_loss: 0.6777 - val_accuracy: 0.8071\n",
      "Epoch 88/150\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.4345 - accuracy: 0.8671 - val_loss: 0.6378 - val_accuracy: 0.8003\n",
      "Epoch 89/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3961 - accuracy: 0.8767 - val_loss: 0.6871 - val_accuracy: 0.8048\n",
      "Epoch 90/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4232 - accuracy: 0.8652 - val_loss: 0.6554 - val_accuracy: 0.8064\n",
      "Epoch 91/150\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.3902 - accuracy: 0.8773 - val_loss: 0.6189 - val_accuracy: 0.8150\n",
      "Epoch 92/150\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.4024 - accuracy: 0.8755 - val_loss: 0.6520 - val_accuracy: 0.7993\n",
      "Epoch 93/150\n",
      "1563/1563 [==============================] - 13s 8ms/step - loss: 0.4244 - accuracy: 0.8655 - val_loss: 0.6820 - val_accuracy: 0.8041\n",
      "Epoch 94/150\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.4001 - accuracy: 0.8749 - val_loss: 0.7975 - val_accuracy: 0.7596\n",
      "Epoch 95/150\n",
      "1563/1563 [==============================] - 12s 8ms/step - loss: 0.3942 - accuracy: 0.8756 - val_loss: 0.6687 - val_accuracy: 0.8116\n",
      "Epoch 96/150\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.4063 - accuracy: 0.8732 - val_loss: 0.6578 - val_accuracy: 0.8088\n",
      "Epoch 97/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4100 - accuracy: 0.8717 - val_loss: 0.7116 - val_accuracy: 0.8092\n",
      "Epoch 98/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3984 - accuracy: 0.8746 - val_loss: 0.6389 - val_accuracy: 0.8115\n",
      "Epoch 99/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4841 - accuracy: 0.8552 - val_loss: 0.6529 - val_accuracy: 0.8147\n",
      "Epoch 100/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3885 - accuracy: 0.8767 - val_loss: 0.6460 - val_accuracy: 0.8209\n",
      "Epoch 101/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3960 - accuracy: 0.8753 - val_loss: 0.6518 - val_accuracy: 0.8079\n",
      "Epoch 102/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3932 - accuracy: 0.8772 - val_loss: 0.6809 - val_accuracy: 0.8025\n",
      "Epoch 103/150\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.4323 - accuracy: 0.8673 - val_loss: 0.7128 - val_accuracy: 0.7961\n",
      "Epoch 104/150\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.4459 - accuracy: 0.8615 - val_loss: 0.6585 - val_accuracy: 0.8091\n",
      "Epoch 105/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3889 - accuracy: 0.8749 - val_loss: 0.7111 - val_accuracy: 0.8145\n",
      "Epoch 106/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4145 - accuracy: 0.8708 - val_loss: 0.6988 - val_accuracy: 0.8039\n",
      "Epoch 107/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4221 - accuracy: 0.8704 - val_loss: 0.6378 - val_accuracy: 0.8145\n",
      "Epoch 108/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4224 - accuracy: 0.8698 - val_loss: 0.6499 - val_accuracy: 0.8157\n",
      "Epoch 109/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4290 - accuracy: 0.8683 - val_loss: 0.6592 - val_accuracy: 0.8135\n",
      "Epoch 110/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4337 - accuracy: 0.8664 - val_loss: 0.6235 - val_accuracy: 0.8073\n",
      "Epoch 111/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4706 - accuracy: 0.8534 - val_loss: 0.6844 - val_accuracy: 0.7970\n",
      "Epoch 112/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4200 - accuracy: 0.8693 - val_loss: 0.6639 - val_accuracy: 0.8183\n",
      "Epoch 113/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4572 - accuracy: 0.8558 - val_loss: 0.6788 - val_accuracy: 0.8103\n",
      "Epoch 114/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4184 - accuracy: 0.8689 - val_loss: 0.6534 - val_accuracy: 0.8020\n",
      "Epoch 115/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4385 - accuracy: 0.8655 - val_loss: 0.6435 - val_accuracy: 0.8139\n",
      "Epoch 116/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.3999 - accuracy: 0.8770 - val_loss: 0.6807 - val_accuracy: 0.7969\n",
      "Epoch 117/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4231 - accuracy: 0.8698 - val_loss: 0.6777 - val_accuracy: 0.7863\n",
      "Epoch 118/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4106 - accuracy: 0.8728 - val_loss: 0.6827 - val_accuracy: 0.7916\n",
      "Epoch 119/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4154 - accuracy: 0.8721 - val_loss: 0.6618 - val_accuracy: 0.8056\n",
      "Epoch 120/150\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.4000 - accuracy: 0.8758 - val_loss: 0.6950 - val_accuracy: 0.8048\n",
      "Epoch 121/150\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.4217 - accuracy: 0.8675 - val_loss: 0.6828 - val_accuracy: 0.7931\n",
      "Epoch 122/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4438 - accuracy: 0.8621 - val_loss: 0.6517 - val_accuracy: 0.7979\n",
      "Epoch 123/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4139 - accuracy: 0.8692 - val_loss: 0.6564 - val_accuracy: 0.8116\n",
      "Epoch 124/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4257 - accuracy: 0.8663 - val_loss: 0.6578 - val_accuracy: 0.8146\n",
      "Epoch 125/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4255 - accuracy: 0.8679 - val_loss: 0.6572 - val_accuracy: 0.8084\n",
      "Epoch 126/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4187 - accuracy: 0.8704 - val_loss: 0.6835 - val_accuracy: 0.7985\n",
      "Epoch 127/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4112 - accuracy: 0.8732 - val_loss: 0.7015 - val_accuracy: 0.7858\n",
      "Epoch 128/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4823 - accuracy: 0.8492 - val_loss: 0.7152 - val_accuracy: 0.7968\n",
      "Epoch 129/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4108 - accuracy: 0.8726 - val_loss: 0.6806 - val_accuracy: 0.8045\n",
      "Epoch 130/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4295 - accuracy: 0.8670 - val_loss: 0.6528 - val_accuracy: 0.8097\n",
      "Epoch 131/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4046 - accuracy: 0.8741 - val_loss: 0.6670 - val_accuracy: 0.8175\n",
      "Epoch 132/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4029 - accuracy: 0.8733 - val_loss: 0.6943 - val_accuracy: 0.8061\n",
      "Epoch 133/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4042 - accuracy: 0.8748 - val_loss: 0.6647 - val_accuracy: 0.8086\n",
      "Epoch 134/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4057 - accuracy: 0.8736 - val_loss: 0.6599 - val_accuracy: 0.8136\n",
      "Epoch 135/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4443 - accuracy: 0.8641 - val_loss: 0.6964 - val_accuracy: 0.7887\n",
      "Epoch 136/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4496 - accuracy: 0.8600 - val_loss: 0.7367 - val_accuracy: 0.7976\n",
      "Epoch 137/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4264 - accuracy: 0.8685 - val_loss: 0.8356 - val_accuracy: 0.7349\n",
      "Epoch 138/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4365 - accuracy: 0.8635 - val_loss: 0.7038 - val_accuracy: 0.8001\n",
      "Epoch 139/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4274 - accuracy: 0.8683 - val_loss: 0.6553 - val_accuracy: 0.8095\n",
      "Epoch 140/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4198 - accuracy: 0.8701 - val_loss: 0.7082 - val_accuracy: 0.7965\n",
      "Epoch 141/150\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.4620 - accuracy: 0.8572 - val_loss: 0.7269 - val_accuracy: 0.7865\n",
      "Epoch 142/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4229 - accuracy: 0.8682 - val_loss: 0.7063 - val_accuracy: 0.8011\n",
      "Epoch 143/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4386 - accuracy: 0.8638 - val_loss: 0.6458 - val_accuracy: 0.8134\n",
      "Epoch 144/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4069 - accuracy: 0.8720 - val_loss: 0.6845 - val_accuracy: 0.7920\n",
      "Epoch 145/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4491 - accuracy: 0.8616 - val_loss: 0.6608 - val_accuracy: 0.8044\n",
      "Epoch 146/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4477 - accuracy: 0.8617 - val_loss: 0.6668 - val_accuracy: 0.7941\n",
      "Epoch 147/150\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.4523 - accuracy: 0.8579 - val_loss: 0.6523 - val_accuracy: 0.8021\n",
      "Epoch 148/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4134 - accuracy: 0.8725 - val_loss: 0.6800 - val_accuracy: 0.7898\n",
      "Epoch 149/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4217 - accuracy: 0.8685 - val_loss: 0.6520 - val_accuracy: 0.8127\n",
      "Epoch 150/150\n",
      "1563/1563 [==============================] - 11s 7ms/step - loss: 0.4299 - accuracy: 0.8667 - val_loss: 0.6791 - val_accuracy: 0.8023\n",
      "Accuracy: 80.23%\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=150, batch_size=32) \n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "model.save('cifar-10-2.h5')\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b8abc396-61c0-48f4-a595-c2b41e07b706",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model \n",
    "model = load_model('cifar-10-2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "93317c4d-ad99-4e63-be49-a53edf9fefc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f8111cb2e0>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np \n",
    "from keras.preprocessing import image\n",
    "import keras.utils as image\n",
    "test_image1 =image.load_img(r\"C:\\Users\\User\\Desktop\\IT\\AI_python\\nn\\train_test\\test\\test\\83519.png\", target_size =(32,32))\n",
    "plt.imshow(test_image1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2ea72ebf-3de4-4246-8005-d49f85ebe0d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n",
      "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]]\n",
      "Horse\n"
     ]
    }
   ],
   "source": [
    "test_image =image.img_to_array(test_image1) \n",
    "test_image =np.expand_dims(test_image, axis =0) \n",
    "result = model.predict(test_image) \n",
    "print(result) \n",
    "if result[0][0]==1: \n",
    "    print(\"Aeroplane\") \n",
    "elif result[0][1]==1: \n",
    "    print('Automobile') \n",
    "elif result[0][2]==1: \n",
    "    print('Bird') \n",
    "elif result[0][3]==1: \n",
    "    print('Cat') \n",
    "elif result[0][4]==1: \n",
    "    print('Deer') \n",
    "elif result[0][5]==1: \n",
    "    print('Dog') \n",
    "elif result[0][6]==1: \n",
    "    print('Frog') \n",
    "elif result[0][7]==1: \n",
    "    print('Horse') \n",
    "elif result[0][8]==1: \n",
    "    print('Ship') \n",
    "elif result[0][9]==1: \n",
    "    print('Truck') \n",
    "else: \n",
    "    print('Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b67c9541-a5ab-427b-8839-ecc7468fbdaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
